"""
LLM API ã‚µãƒ¼ãƒ“ã‚¹
Google PaLM API ã‚’ãƒ¡ã‚¤ãƒ³ã«ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ä»˜ã
"""

import httpx
import json
import os
from typing import Dict, List, Any, Tuple
from datetime import datetime

class LLMAPIService:
    """LLM API ã‚µãƒ¼ãƒ“ã‚¹"""
    
    def __init__(self):
        self.providers = {
            'openai_gpt4': OpenAIClient(),
            'openrouter_claude': OpenRouterClient('anthropic/claude-3.5-sonnet'),
            'openrouter_gpt4o': OpenRouterClient('openai/gpt-4o'),
            'openrouter_gemini': OpenRouterClient('google/gemini-pro')
        }
        # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’å–å¾—
        self.current_provider = os.getenv("DEFAULT_LLM_PROVIDER", "openai_gpt4")
        self.last_token_count = 0
        
    async def reconstruct_message(
        self, 
        summary: str, 
        slots: Dict[str, Any], 
        style_preset: str, 
        language: str, 
        neighbors: List[Dict[str, Any]]
    ) -> Tuple[str, float]:
        """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å†æ§‹æˆ"""
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
        prompt = self._build_reconstruction_prompt(
            summary, slots, style_preset, language, neighbors
        )
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ä»˜ãAPIå‘¼ã³å‡ºã—
        for provider_name, provider in self.providers.items():
            try:
                response = await provider.generate(
                    prompt=prompt,
                    max_tokens=200,
                    temperature=0.7
                )
                
                self.current_provider = provider_name
                self.last_token_count = response.get('token_count', 0)
                
                return response['text'], response.get('confidence', 0.8)
                
            except Exception as e:
                print(f"Provider {provider_name} failed: {e}")
                continue
        
        # ã™ã¹ã¦ã®ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ãŒå¤±æ•—ã—ãŸå ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        print("âš ï¸  All LLM providers failed, using fallback reconstruction")
        return self._fallback_reconstruction(summary, style_preset, language)
    
    def _build_reconstruction_prompt(
        self, 
        summary: str, 
        slots: Dict[str, Any], 
        style_preset: str, 
        language: str, 
        neighbors: List[Dict[str, Any]]
    ) -> str:
        """å†æ§‹æˆç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰"""
        
        style_instructions = {
            'biz_formal': 'ãƒ“ã‚¸ãƒã‚¹ç”¨ã®ä¸å¯§ãªæ•¬èªã§ã€çµè«–ã‚’å…ˆã«è¿°ã¹ã€ç½²åã‚’ä»˜ã‘ã¦ãã ã•ã„ã€‚',
            'emoji_casual': 'ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«ã§è¦ªã—ã¿ã‚„ã™ã„æ–‡ä½“ã§ã€é©åº¦ã«çµµæ–‡å­—ã‚’ä½¿ã£ã¦ãã ã•ã„ã€‚',
            'technical': 'æŠ€è¡“çš„ã§æ­£ç¢ºãªè¡¨ç¾ã‚’ä½¿ã„ã€å°‚é–€ç”¨èªã‚’é©åˆ‡ã«ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚'
        }
        
        prompt = f"""
ä»¥ä¸‹ã®è¦ç´„ã‚’{language}ã§{style_instructions.get(style_preset, 'è‡ªç„¶ãªæ–‡ä½“ã§')}å†æ§‹æˆã—ã¦ãã ã•ã„ã€‚

è¦ç´„: {summary}
ã‚¹ãƒ­ãƒƒãƒˆ: {json.dumps(slots, ensure_ascii=False)}
å‚è€ƒæƒ…å ±: {json.dumps(neighbors, ensure_ascii=False)}

åˆ¶ç´„:
- å…ƒã®æ„å‘³ã‚’ä¿æŒã™ã‚‹
- æŒ‡å®šã•ã‚ŒãŸã‚¹ã‚¿ã‚¤ãƒ«ã«å¾“ã†
- 100æ–‡å­—ä»¥å†…
- è‡ªç„¶ã§èª­ã¿ã‚„ã™ã„æ–‡ç« ã«ã™ã‚‹
"""
        return prompt
    
    def _fallback_reconstruction(self, summary: str, style_preset: str, language: str) -> Tuple[str, float]:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®ç°¡å˜ãªå†æ§‹æˆ"""
        
        # ã‚¹ã‚¿ã‚¤ãƒ«ã«å¿œã˜ãŸç°¡å˜ãªå¤‰æ›
        if style_preset == 'emoji_casual':
            if language == 'ja':
                reconstructed = f"ã“ã‚“ã«ã¡ã¯ï¼ğŸ˜Š {summary} ã«ã¤ã„ã¦ä½•ã‹ãŠè©±ã—ã—ãŸã„ã“ã¨ãŒã‚ã‚‹ã®ï¼Ÿ"
            else:
                reconstructed = f"Hi! ğŸ˜Š What would you like to talk about regarding {summary}?"
        elif style_preset == 'biz_formal':
            if language == 'ja':
                reconstructed = f"ãŠç–²ã‚Œæ§˜ã§ã™ã€‚{summary} ã«ã¤ã„ã¦ã”ç›¸è«‡ãŒã”ã–ã„ã¾ã™ã€‚"
            else:
                reconstructed = f"Good day. I would like to discuss {summary} with you."
        else:  # technical or default
            if language == 'ja':
                reconstructed = f"æŠ€è¡“çš„ãªå†…å®¹ã«ã¤ã„ã¦: {summary}"
            else:
                reconstructed = f"Technical discussion: {summary}"
        
        return reconstructed, 0.5  # ä½ã„ä¿¡é ¼åº¦

class OpenRouterClient:
    """OpenRouter API ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"""
    
    def __init__(self, model: str):
        self.model = model
        self.api_key = os.getenv("OPENROUTER_API_KEY")
        self.base_url = "https://openrouter.ai/api/v1"
        
    async def generate(self, prompt: str, max_tokens: int = 200, temperature: float = 0.7) -> Dict[str, Any]:
        """OpenRouter API ã§ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ"""
        if not self.api_key:
            raise Exception("OpenRouter API key not configured")
        
        url = f"{self.base_url}/chat/completions"
        
        payload = {
            "model": self.model,
            "messages": [{"role": "user", "content": prompt}],
            "max_tokens": max_tokens,
            "temperature": temperature
        }
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
            "HTTP-Referer": "https://sensechat-mvp.local",
            "X-Title": "SenseChat MVP"
        }
        
        async with httpx.AsyncClient() as client:
            response = await client.post(url, json=payload, headers=headers)
            response.raise_for_status()
            
            data = response.json()
            text = data["choices"][0]["message"]["content"]
            
            return {
                "text": text,
                "confidence": 0.9,
                "token_count": data["usage"]["total_tokens"]
            }

class OpenAIClient:
    """OpenAI API ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆGPT-4ï¼‰"""
    
    def __init__(self):
        self.api_key = os.getenv("OPENAI_API_KEY")
        self.base_url = "https://api.openai.com/v1"
        
    async def generate(self, prompt: str, max_tokens: int = 200, temperature: float = 0.7) -> Dict[str, Any]:
        """OpenAI GPT-4 API ã§ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ"""
        if not self.api_key:
            raise Exception("OpenAI API key not configured")
        
        url = f"{self.base_url}/chat/completions"
        
        payload = {
            "model": "gpt-4",
            "messages": [{"role": "user", "content": prompt}],
            "max_tokens": max_tokens,
            "temperature": temperature
        }
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        async with httpx.AsyncClient() as client:
            response = await client.post(url, json=payload, headers=headers)
            response.raise_for_status()
            
            data = response.json()
            text = data["choices"][0]["message"]["content"]
            
            return {
                "text": text,
                "confidence": 0.95,
                "token_count": data["usage"]["total_tokens"]
            }

# AnthropicClient ã¯ OpenRouterClient ã«çµ±åˆã•ã‚ŒãŸãŸã‚å‰Šé™¤
